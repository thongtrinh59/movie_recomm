{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import boto3\n",
    "# from botocore.config import Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\trinh\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3166: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv('movies_metadata.csv')\n",
    "credits_ = pd.read_csv('credits.csv')\n",
    "keywords = pd.read_csv('keywords.csv')\n",
    "\n",
    "metadata = metadata.iloc[0:10000,:]\n",
    "credits_ = credits_.iloc[0:10000,:]\n",
    "keywords = keywords.iloc[0:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords['id'] = keywords['id'].astype('int')\n",
    "credits_['id'] = credits_['id'].astype('int')\n",
    "metadata['id'] = metadata['id'].astype('int')\n",
    "\n",
    "# keywords.loc[0]['keywords']\n",
    "# credits_.loc[0]['crew']\n",
    "# metadata.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata.merge(credits_, on='id')\n",
    "metadata = metadata.merge(keywords, on='id')\n",
    "\n",
    "features = ['cast', 'crew', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    metadata[feature] = metadata[feature].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [{'credit_id': '52fe4284c3a36847f8024f49', 'de...\n",
       "1        [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...\n",
       "2        [{'credit_id': '52fe466a9251416c75077a89', 'de...\n",
       "3        [{'credit_id': '52fe44779251416c91011acb', 'de...\n",
       "4        [{'credit_id': '52fe44959251416c75039ed7', 'de...\n",
       "                               ...                        \n",
       "10013    [{'credit_id': '5712c499c3a368673d004567', 'de...\n",
       "10014    [{'credit_id': '52fe44f2c3a36847f80b356d', 'de...\n",
       "10015    [{'credit_id': '57cb6aee92514163dd003b6e', 'de...\n",
       "10016    [{'credit_id': '532116ff9251411f890020a3', 'de...\n",
       "10017    [{'credit_id': '52fe45659251416c75055007', 'de...\n",
       "Name: crew, Length: 10018, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# metadata.loc[0]['keywords']\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan\n",
    "\n",
    "metadata['director'] = metadata['crew'].apply(get_director)\n",
    "\n",
    "metadata['crew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [Tom Hanks, Tim Allen, Don Rickles]\n",
       "1           [Robin Williams, Jonathan Hyde, Kirsten Dunst]\n",
       "2               [Walter Matthau, Jack Lemmon, Ann-Margret]\n",
       "3        [Whitney Houston, Angela Bassett, Loretta Devine]\n",
       "4               [Steve Martin, Diane Keaton, Martin Short]\n",
       "                               ...                        \n",
       "10013    [Emma Gramatica, Francesco Golisano, Paolo Sto...\n",
       "10014        [Max Riemelt, Tom Schilling, Jonas JÃ¤germeyr]\n",
       "10015            [Gene Wilder, Harrison Ford, Ramon Bieri]\n",
       "10016         [Sachiko Kokubu, Mansai Nomura, Hideaki Ito]\n",
       "10017                  [Beanie Sigel, Noreaga, Damon Dash]\n",
       "Name: cast, Length: 10018, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_list(x):\n",
    "    if isinstance(x, list):\n",
    "        names = [i['name'] for i in x]\n",
    "        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.\n",
    "        if len(names) > 3:\n",
    "            names = names[:3]\n",
    "        return names\n",
    "\n",
    "    #Return empty list in case of missing/malformed data\n",
    "    return []\n",
    "\n",
    "features = ['cast', 'keywords', 'genres']\n",
    "for feature in features:\n",
    "    metadata[feature] = metadata[feature].apply(get_list)\n",
    "\n",
    "\n",
    "metadata['cast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     [jealousy, toy, boy]\n",
       "1        [boardgame, disappearance, basedonchildren'sbook]\n",
       "2              [fishing, bestfriend, duringcreditsstinger]\n",
       "3        [basedonnovel, interracialrelationship, single...\n",
       "4                        [baby, midlifecrisis, confidence]\n",
       "                               ...                        \n",
       "10013                             [magic, poverty, orphan]\n",
       "10014                 [transporter, nazis, boardingschool]\n",
       "10015                                                   []\n",
       "10016                                                   []\n",
       "10017                              [drugsmuggle, criminal]\n",
       "Name: keywords, Length: 10018, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    else:\n",
    "        #Check if director exists. If not, return empty string\n",
    "        if isinstance(x, str):\n",
    "            return str.lower(x.replace(\" \", \"\"))\n",
    "        else:\n",
    "            return ''\n",
    "\n",
    "features = ['cast', 'keywords', 'director', 'genres']\n",
    "\n",
    "for feature in features:\n",
    "    metadata[feature] = metadata[feature].apply(clean_data)\n",
    "\n",
    "metadata['keywords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        jealousy toy boy tomhanks timallen donrickles ...\n",
       "1        boardgame disappearance basedonchildren'sbook ...\n",
       "2        fishing bestfriend duringcreditsstinger walter...\n",
       "3        basedonnovel interracialrelationship singlemot...\n",
       "4        baby midlifecrisis confidence stevemartin dian...\n",
       "                               ...                        \n",
       "10013    magic poverty orphan emmagramatica francescogo...\n",
       "10014    transporter nazis boardingschool maxriemelt to...\n",
       "10015     genewilder harrisonford ramonbieri robertaldr...\n",
       "10016     sachikokokubu mansainomura hideakiito yojirot...\n",
       "10017    drugsmuggle criminal beaniesigel noreaga damon...\n",
       "Name: soup, Length: 10018, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_soup(x):\n",
    "    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])\n",
    "\n",
    "metadata['soup'] = metadata.apply(create_soup, axis=1)\n",
    "\n",
    "metadata['soup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drugsmuggle criminal beaniesigel noreaga damondash damondash action adventure crime\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Two Thousand Maniacs!', 'tt0058694', 87.0, '1964-03-20', 6.2],\n",
       " ['Saw', 'tt0387564', 103.0, '2004-10-01', 7.2],\n",
       " ['Ju-on: The Curse', 'tt0330500', 70.0, '2000-02-11', 7.0],\n",
       " ['House on the Edge of the Park', 'tt0080503', 91.0, '1980-11-06', 5.8],\n",
       " ['Theatre of Blood', 'tt0070791', 104.0, '1973-03-15', 6.7],\n",
       " ['Long Time Dead', 'tt0251806', 94.0, '2002-01-18', 4.5],\n",
       " ['Faces of Death: Fact or Fiction?', 'tt0223251', 54.0, '1999-01-01', 0.0],\n",
       " ['The Mesmerist', 'tt0272730', 95.0, '2002-03-11', 0.0],\n",
       " ['Faces of Death II', 'tt0085518', 85.0, '1981-11-10', 3.3],\n",
       " ['Faces of Death III', 'tt0121261', 86.0, '1985-03-10', 3.4]]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_recommendation(query, metadata=metadata):\n",
    "  \n",
    "  new_row = metadata.iloc[-1,:].copy()\n",
    "  \n",
    "  new_row.iloc[-1] = query\n",
    "  \n",
    "  metadata = metadata.append(new_row)\n",
    "#   print(metadata.iloc[-1,:])\n",
    "  \n",
    "  count = CountVectorizer(stop_words='english')\n",
    "  count_matrix = count.fit_transform(metadata['soup'])\n",
    "\n",
    "  cosine_sim2 = cosine_similarity(count_matrix, count_matrix)\n",
    "  \n",
    "  sim_scores = list(enumerate(cosine_sim2[-1,:]))\n",
    "  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "  ranked_titles = []\n",
    "  for i in range(1, 11):\n",
    "    indx = sim_scores[i][0]\n",
    "    ranked_titles.append([metadata['title'].iloc[indx], metadata['imdb_id'].iloc[indx], metadata['runtime'].iloc[indx], metadata['release_date'].iloc[indx], metadata['vote_average'].iloc[indx]])\n",
    "  \n",
    "  return ranked_titles\n",
    "\n",
    "\n",
    "query = \"horror jameswan dreadful\"\n",
    "\n",
    "make_recommendation(query, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
